{\rtf1\ansi\ansicpg1252\cocoartf1404\cocoasubrtf470
{\fonttbl\f0\fnil\fcharset0 HelveticaNeue;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue233;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sl320\partightenfactor0

\f0\fs28 \cf0 \expnd0\expndtw0\kerning0
good resource \
\pard\pardeftab720\sl320\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://www.reddit.com/r/deepdream/comments/3cawxb/what_are_deepdream_images_how_do_i_make_my_own/"}}{\fldrslt \cf2 \ul \ulc2 https://www.reddit.com/r/deepdream/comments/3cawxb/what_are_deepdream_images_how_do_i_make_my_own/}}\
\pard\pardeftab720\sl340\partightenfactor0

\b \cf0 \
On alternative datasets (less dog)
\b0 \

\b \
\pard\pardeftab720\sl320\partightenfactor0

\b0 \cf0 https://github.com/BVLC/caffe/tree/master/models/bvlc_googlenet \'a0\'a0 \
http://www.image-net.org \
https://github.com/BVLC/caffe/wiki/Model-Zoo \
http://places.csail.mit.edu/downloadCNN.html \
http://places.csail.mit.edu \
\
\pard\pardeftab720\sl340\partightenfactor0

\b \cf0 for audio based dreams
\b0 \
Recurrent\'a0Neural\'a0Network\'a0(RNN)\'a0is\'a0also\'a0a\'a0good\'a0avenue \
https://soundcloud.com/graphific/sets/rnn-against-the-machine \
\

\b VIDEO
\b0 \
https://github.com/graphific/DeepDreamVideo \
\
\

\b GLITCHES
\b0 \
http://www.hellocatfood.com/databending-using-audacity/\'a0not\'a0deep\'a0dream\'a0but\'a0cool \
\
\
\
\
++ readings \
\pard\pardeftab720\sl320\partightenfactor0
{\field{\*\fldinst{HYPERLINK "http://arxiv.org/pdf/1409.4842.pdf"}}{\fldrslt \cf2 \ul \ulc2 http://arxiv.org/pdf/1409.4842.pdf}}\
\pard\pardeftab720\sl320\partightenfactor0
{\field{\*\fldinst{HYPERLINK "http://googleresearch.blogspot.ca/2015/06/inceptionism-going-deeper-into-neural.html"}}{\fldrslt \cf2 \ul \ulc2 http://googleresearch.blogspot.ca/2015/06/inceptionism-going-deeper-into-neural.html}}\
\pard\pardeftab720\sl320\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://www.reddit.com/r/explainlikeimfive/comments/3cbelv/eli5_can_anyone_explain_googles_deep_dream/"}}{\fldrslt \cf2 \ul \ulc2 https://www.reddit.com/r/explainlikeimfive/comments/3cbelv/eli5_can_anyone_explain_googles_deep_dream/}}\
\pard\pardeftab720\sl320\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://317070.github.io/Dream/"}}{\fldrslt \cf2 \ul \ulc2 https://317070.github.io/Dream/}}\'a0< twitch live stream of another method \
\
j>>> \
\pard\pardeftab720\sl320\partightenfactor0
{\field{\*\fldinst{HYPERLINK "http://googleresearch.blogspot.ca/2014/09/building-deeper-understanding-of-images.html"}}{\fldrslt \cf2 \ul \ulc2 http://googleresearch.blogspot.ca/2014/09/building-deeper-understanding-of-images.html}}\'a0< image classification \
\pard\pardeftab720\sl320\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://www.youtube.com/watch?v=yxxRAHVtafI"}}{\fldrslt \cf2 \ul \ulc2 https://www.youtube.com/watch?v=yxxRAHVtafI}}\'a0speech recognition \
\pard\pardeftab720\sl320\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/Backpropagation"}}{\fldrslt \cf2 \ul \ulc2 https://en.wikipedia.org/wiki/Backpropagation}}\'a0< adjusting the parameters \
\
\
fine tuning flickr style \
\pard\pardeftab720\sl320\partightenfactor0
{\field{\*\fldinst{HYPERLINK "http://caffe.berkeleyvision.org/gathered/examples/finetune_flickr_style.html"}}{\fldrslt \cf2 \ul \ulc2 http://caffe.berkeleyvision.org/gathered/examples/finetune_flickr_style.html}}\
more on imagenet\'a0 \
\pard\pardeftab720\sl320\partightenfactor0
{\field{\*\fldinst{HYPERLINK "http://caffe.berkeleyvision.org/gathered/examples/imagenet.html"}}{\fldrslt \cf2 \ul \ulc2 http://caffe.berkeleyvision.org/gathered/examples/imagenet.html}}\
\
>>>> other libs \
\pard\pardeftab720\sl320\partightenfactor0
{\field{\*\fldinst{HYPERLINK "http://deeplearning.net/software/theano/"}}{\fldrslt \cf2 \ul \ulc2 http://deeplearning.net/software/theano/}}\
\pard\pardeftab720\sl320\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://github.com/Lasagne/Lasagne"}}{\fldrslt \cf2 \ul \ulc2 https://github.com/Lasagne/Lasagne}}\
}